{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.datasets.ukbiobank_dataset import UkBiobankDatasetArgs\n",
    "from src.experiments.multi_ds_vessel_experiment import MultiDSVesselExperimentArgs\n",
    "from src.args.yaml_config import YamlConfig\n",
    "from src.models.auto_sam_model import AutoSamModel\n",
    "from torch.utils.data import DataLoader\n",
    "from src.datasets.ukbiobank_dataset import UkBiobankDataset\n",
    "from typing import cast\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from src.datasets.base_dataset import Batch\n",
    "\n",
    "import torch\n",
    "\n",
    "# Mask output path\n",
    "iteration = 0\n",
    "output_path = f\"/dhc/dsets/retina_masks/v{iteration}\"\n",
    "\n",
    "# Setup configs\n",
    "yaml_config = YamlConfig().config\n",
    "experiment_config = MultiDSVesselExperimentArgs(\n",
    "    sam_model='vit_b', \n",
    "    experiment_id='label_generation', \n",
    "    prompt_encoder_checkpoint='/dhc/groups/mp2024cl2/results/drive_experiment/2024-11-15_11#24#47/prompt_encoder.pt',\n",
    "    sam_checkpoint='/dhc/groups/mp2024cl2/sam_vit_b.pth',\n",
    "    hard_net_cp='/dhc/groups/mp2024cl2/hardnet68.pth',\n",
    "    batch_size=1,\n",
    ")\n",
    "ds_config = UkBiobankDatasetArgs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dhc/home/leon.hermann/MP/mp-lippert-experiments/src/models/segment_anything/build_sam.py:105: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(f)\n",
      "/dhc/home/leon.hermann/MP/mp-lippert-experiments/src/models/auto_sam_prompt_encoder/hardnet.py:228: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.load_state_dict(torch.load(hard_net_cp))\n",
      "/tmp/ipykernel_1053189/4282286059.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(experiment_config.prompt_encoder_checkpoint, map_location=\"cuda\"),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ImageNet pretrained weights for HarDNet68 is loaded\n",
      "loading prompt-encoder model from checkpoint /dhc/groups/mp2024cl2/results/drive_experiment/2024-11-15_11#24#47/prompt_encoder.pt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AutoSamModel(\n",
       "  (sam): SamBatched(\n",
       "    (image_encoder): ImageEncoderViT(\n",
       "      (patch_embed): PatchEmbed(\n",
       "        (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "      )\n",
       "      (blocks): ModuleList(\n",
       "        (0-11): 12 x Block(\n",
       "          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): MLPBlock(\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (neck): Sequential(\n",
       "        (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): LayerNorm2d()\n",
       "        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (3): LayerNorm2d()\n",
       "      )\n",
       "    )\n",
       "    (prompt_encoder): PromptEncoder(\n",
       "      (pe_layer): PositionEmbeddingRandom()\n",
       "      (point_embeddings): ModuleList(\n",
       "        (0-3): 4 x Embedding(1, 256)\n",
       "      )\n",
       "      (not_a_point_embed): Embedding(1, 256)\n",
       "      (mask_downscaling): Sequential(\n",
       "        (0): Conv2d(1, 4, kernel_size=(2, 2), stride=(2, 2))\n",
       "        (1): LayerNorm2d()\n",
       "        (2): GELU(approximate='none')\n",
       "        (3): Conv2d(4, 16, kernel_size=(2, 2), stride=(2, 2))\n",
       "        (4): LayerNorm2d()\n",
       "        (5): GELU(approximate='none')\n",
       "        (6): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (no_mask_embed): Embedding(1, 256)\n",
       "    )\n",
       "    (mask_decoder): MaskDecoder(\n",
       "      (transformer): TwoWayTransformer(\n",
       "        (layers): ModuleList(\n",
       "          (0-1): 2 x TwoWayAttentionBlock(\n",
       "            (self_attn): Attention(\n",
       "              (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            )\n",
       "            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (cross_attn_token_to_image): Attention(\n",
       "              (q_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "              (k_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "              (v_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "              (out_proj): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): MLPBlock(\n",
       "              (lin1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "              (lin2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (cross_attn_image_to_token): Attention(\n",
       "              (q_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "              (k_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "              (v_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "              (out_proj): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (final_attn_token_to_image): Attention(\n",
       "          (q_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "          (k_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "          (v_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "          (out_proj): Linear(in_features=128, out_features=256, bias=True)\n",
       "        )\n",
       "        (norm_final_attn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (iou_token): Embedding(1, 256)\n",
       "      (mask_tokens): Embedding(4, 256)\n",
       "      (output_upscaling): Sequential(\n",
       "        (0): ConvTranspose2d(256, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "        (1): LayerNorm2d()\n",
       "        (2): GELU(approximate='none')\n",
       "        (3): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))\n",
       "        (4): GELU(approximate='none')\n",
       "      )\n",
       "      (output_hypernetworks_mlps): ModuleList(\n",
       "        (0-3): 4 x MLP(\n",
       "          (layers): ModuleList(\n",
       "            (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)\n",
       "            (2): Linear(in_features=256, out_features=32, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (iou_prediction_head): MLP(\n",
       "        (layers): ModuleList(\n",
       "          (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)\n",
       "          (2): Linear(in_features=256, out_features=4, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (bce_loss): BCELoss()\n",
       "  (prompt_encoder): ModelEmb(\n",
       "    (backbone): HarDNet(\n",
       "      (base): ModuleList(\n",
       "        (0): ConvLayer(\n",
       "          (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvLayer(\n",
       "          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "        (3): HarDBlock(\n",
       "          (layers): ModuleList(\n",
       "            (0): ConvLayer(\n",
       "              (conv): Conv2d(64, 14, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (1): ConvLayer(\n",
       "              (conv): Conv2d(78, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (2): ConvLayer(\n",
       "              (conv): Conv2d(24, 14, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (3): ConvLayer(\n",
       "              (conv): Conv2d(102, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (4): ConvLayer(\n",
       "              (conv): Conv2d(40, 14, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (5): ConvLayer(\n",
       "              (conv): Conv2d(54, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (6): ConvLayer(\n",
       "              (conv): Conv2d(24, 14, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (7): ConvLayer(\n",
       "              (conv): Conv2d(142, 68, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(68, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (4): ConvLayer(\n",
       "          (conv): Conv2d(124, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU6(inplace=True)\n",
       "        )\n",
       "        (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (6): HarDBlock(\n",
       "          (layers): ModuleList(\n",
       "            (0): ConvLayer(\n",
       "              (conv): Conv2d(128, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (1): ConvLayer(\n",
       "              (conv): Conv2d(144, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (2): ConvLayer(\n",
       "              (conv): Conv2d(28, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (3): ConvLayer(\n",
       "              (conv): Conv2d(172, 46, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(46, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (4): ConvLayer(\n",
       "              (conv): Conv2d(46, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (5): ConvLayer(\n",
       "              (conv): Conv2d(62, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (6): ConvLayer(\n",
       "              (conv): Conv2d(28, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (7): ConvLayer(\n",
       "              (conv): Conv2d(218, 78, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(78, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (8): ConvLayer(\n",
       "              (conv): Conv2d(78, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (9): ConvLayer(\n",
       "              (conv): Conv2d(94, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (10): ConvLayer(\n",
       "              (conv): Conv2d(28, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (11): ConvLayer(\n",
       "              (conv): Conv2d(122, 46, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(46, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (12): ConvLayer(\n",
       "              (conv): Conv2d(46, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (13): ConvLayer(\n",
       "              (conv): Conv2d(62, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (14): ConvLayer(\n",
       "              (conv): Conv2d(28, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (15): ConvLayer(\n",
       "              (conv): Conv2d(296, 134, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(134, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (7): ConvLayer(\n",
       "          (conv): Conv2d(262, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU6(inplace=True)\n",
       "        )\n",
       "        (8): HarDBlock(\n",
       "          (layers): ModuleList(\n",
       "            (0): ConvLayer(\n",
       "              (conv): Conv2d(256, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (1): ConvLayer(\n",
       "              (conv): Conv2d(276, 34, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(34, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (2): ConvLayer(\n",
       "              (conv): Conv2d(34, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (3): ConvLayer(\n",
       "              (conv): Conv2d(310, 58, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (4): ConvLayer(\n",
       "              (conv): Conv2d(58, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (5): ConvLayer(\n",
       "              (conv): Conv2d(78, 34, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(34, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (6): ConvLayer(\n",
       "              (conv): Conv2d(34, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (7): ConvLayer(\n",
       "              (conv): Conv2d(368, 98, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(98, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (8): ConvLayer(\n",
       "              (conv): Conv2d(98, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (9): ConvLayer(\n",
       "              (conv): Conv2d(118, 34, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(34, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (10): ConvLayer(\n",
       "              (conv): Conv2d(34, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (11): ConvLayer(\n",
       "              (conv): Conv2d(152, 58, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (12): ConvLayer(\n",
       "              (conv): Conv2d(58, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (13): ConvLayer(\n",
       "              (conv): Conv2d(78, 34, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(34, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (14): ConvLayer(\n",
       "              (conv): Conv2d(34, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (15): ConvLayer(\n",
       "              (conv): Conv2d(466, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(168, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (9): ConvLayer(\n",
       "          (conv): Conv2d(328, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU6(inplace=True)\n",
       "        )\n",
       "        (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (11): HarDBlock(\n",
       "          (layers): ModuleList(\n",
       "            (0): ConvLayer(\n",
       "              (conv): Conv2d(320, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (1): ConvLayer(\n",
       "              (conv): Conv2d(360, 68, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(68, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (2): ConvLayer(\n",
       "              (conv): Conv2d(68, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (3): ConvLayer(\n",
       "              (conv): Conv2d(428, 116, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (4): ConvLayer(\n",
       "              (conv): Conv2d(116, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (5): ConvLayer(\n",
       "              (conv): Conv2d(156, 68, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(68, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (6): ConvLayer(\n",
       "              (conv): Conv2d(68, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (7): ConvLayer(\n",
       "              (conv): Conv2d(544, 196, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (8): ConvLayer(\n",
       "              (conv): Conv2d(196, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (9): ConvLayer(\n",
       "              (conv): Conv2d(236, 68, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(68, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (10): ConvLayer(\n",
       "              (conv): Conv2d(68, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (11): ConvLayer(\n",
       "              (conv): Conv2d(304, 116, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (12): ConvLayer(\n",
       "              (conv): Conv2d(116, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (13): ConvLayer(\n",
       "              (conv): Conv2d(156, 68, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(68, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (14): ConvLayer(\n",
       "              (conv): Conv2d(68, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (15): ConvLayer(\n",
       "              (conv): Conv2d(740, 334, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(334, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (12): ConvLayer(\n",
       "          (conv): Conv2d(654, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU6(inplace=True)\n",
       "        )\n",
       "        (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (14): HarDBlock(\n",
       "          (layers): ModuleList(\n",
       "            (0): ConvLayer(\n",
       "              (conv): Conv2d(640, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (1): ConvLayer(\n",
       "              (conv): Conv2d(800, 272, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(272, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (2): ConvLayer(\n",
       "              (conv): Conv2d(272, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (3): ConvLayer(\n",
       "              (conv): Conv2d(1072, 462, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(462, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (15): ConvLayer(\n",
       "          (conv): Conv2d(782, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU6(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (decoder): SmallDecoder(\n",
       "      (up1): UpBlockSkip(\n",
       "        (Upsample): Upsample(scale_factor=2.0, mode='bilinear')\n",
       "        (conv1): Conv2d(960, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv1_drop): Dropout2d(p=0, inplace=False)\n",
       "        (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2_drop): Dropout2d(p=0, inplace=False)\n",
       "        (BN): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (up2): UpBlockSkip(\n",
       "        (Upsample): Upsample(scale_factor=2.0, mode='bilinear')\n",
       "        (conv1): Conv2d(448, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv1_drop): Dropout2d(p=0, inplace=False)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2_drop): Dropout2d(p=0, inplace=False)\n",
       "        (BN): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (final): CNNBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv1_drop): Dropout2d(p=0, inplace=False)\n",
       "        (conv2_drop): Dropout2d(p=0, inplace=False)\n",
       "        (BN1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (BN2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load pretrained model\n",
    "model = AutoSamModel(experiment_config)\n",
    "if experiment_config.prompt_encoder_checkpoint is not None:\n",
    "    print(\n",
    "        f\"loading prompt-encoder model from checkpoint {experiment_config.prompt_encoder_checkpoint}\"\n",
    "    )\n",
    "    model.prompt_encoder.load_state_dict(\n",
    "        torch.load(experiment_config.prompt_encoder_checkpoint, map_location=\"cuda\"),\n",
    "        strict=True,\n",
    "    )\n",
    "model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/168247 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 372/168247 [00:37<4:39:32, 10.01it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m label \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     14\u001b[0m     mask_out_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_p\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 15\u001b[0m     image, mask  \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msegment_image_from_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_p\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m     mask[mask \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m255\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m\n\u001b[1;32m     17\u001b[0m     mask[mask \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/MP/mp-lippert-experiments/src/models/auto_sam_model.py:162\u001b[0m, in \u001b[0;36mAutoSamModel.segment_image_from_file\u001b[0;34m(self, image_path)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[1;32m    161\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(cv2\u001b[38;5;241m.\u001b[39mimread(image_path), cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB)\n\u001b[0;32m--> 162\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msegment_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/MP/mp-lippert-experiments/src/models/auto_sam_model.py:152\u001b[0m, in \u001b[0;36mAutoSamModel.segment_image\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m    147\u001b[0m     mask \u001b[38;5;241m=\u001b[39m sam_call(input_images, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msam, dense_embeddings)\n\u001b[1;32m    149\u001b[0m mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msam\u001b[38;5;241m.\u001b[39mpostprocess_masks(\n\u001b[1;32m    150\u001b[0m     mask, input_size\u001b[38;5;241m=\u001b[39minput_size, original_size\u001b[38;5;241m=\u001b[39moriginal_size\n\u001b[1;32m    151\u001b[0m )\n\u001b[0;32m--> 152\u001b[0m mask \u001b[38;5;241m=\u001b[39m \u001b[43mmask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m    153\u001b[0m mask \u001b[38;5;241m=\u001b[39m (mask \u001b[38;5;241m-\u001b[39m mask\u001b[38;5;241m.\u001b[39mmin()) \u001b[38;5;241m/\u001b[39m (mask\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m-\u001b[39m mask\u001b[38;5;241m.\u001b[39mmin())\n\u001b[1;32m    154\u001b[0m mask \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m255\u001b[39m \u001b[38;5;241m*\u001b[39m mask)\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39muint8)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from pathlib import Path\n",
    "\n",
    "# Create output folder if it does not exist\n",
    "Path(output_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "filtered_samples_filepath = ds_config.filter_scores_filepath\n",
    "\n",
    "with open(filtered_samples_filepath, 'r') as f:\n",
    "    for sample in tqdm(f.readlines()[1:]):\n",
    "        file_p, neg_prob, pos_prob, label = sample.strip().split(',')\n",
    "        \n",
    "        if label == '1':\n",
    "            mask_out_path = f\"{output_path}/{file_p.split('/')[-1]}\"\n",
    "            image, mask  = model.segment_image_from_file(file_p)\n",
    "            mask[mask > 255 / 2] = 255\n",
    "            mask[mask <= 255 / 2] = 0\n",
    "            mask_img = mask * np.array([1, 1, 1])\n",
    "            cv2.imwrite(mask_out_path, mask_img)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
